set_transformer:
  batch_size: 64
  device: cuda
  dropout: 0.1
  epochs: 50
  hidden_dim: 128
  lr: 0.0001
  num_heads: 4
  num_layers: 3
