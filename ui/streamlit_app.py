import streamlit as st
import pandas as pd
import numpy as np
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
import io
import base64
from datetime import datetime
import warnings
import os
import sys

# Dodaj Å›cieÅ¼ki do moduÅ‚Ã³w
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
sys.path.append(os.path.join(os.path.dirname(__file__), '../src'))

# Funkcja log_operation - przeniesiona na poczÄ…tek pliku

def log_operation(operation, details, function_name=None, button_name=None, data_stats=None):
    """Funkcja do logowania operacji na danych z rozszerzonymi informacjami diagnostycznymi"""
    # Tworzymy folder logs jeÅ›li nie istnieje
    if not os.path.exists('data/logs'):
        os.makedirs('data/logs')
    # Generujemy nazwÄ™ pliku z datÄ…
    current_date = datetime.now().strftime('%Y-%m-%d')
    log_file = f'data/logs/app_log_{current_date}.txt'
    # Formatujemy wiadomoÅ›Ä‡ z czasem
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    log_message = f"\n[{timestamp}] === OPERACJA: {operation} ===\n"
    # Dodajemy informacje o funkcji
    if function_name:
        log_message += f"Funkcja: {function_name}\n"
    # Dodajemy informacje o przycisku
    if button_name:
        log_message += f"Przycisk: {button_name}\n"
    # Dodajemy szczegÃ³Å‚y operacji
    log_message += f"SzczegÃ³Å‚y: {details}\n"
    # Dodajemy statystyki danych jeÅ›li dostÄ™pne
    if data_stats:
        log_message += f"Statystyki danych:\n{data_stats}\n"
    log_message += "=" * 50
    # Zapisujemy do pliku
    with open(log_file, 'a', encoding='utf-8') as f:
        f.write(log_message)
    # WyÅ›wietlamy teÅ¼ w konsoli
    print(log_message)

from utils.data_manager import load_working_data, save_working_data, initialize_working_data
from data_analysis.correlation import create_correlation_matrix, analyze_correlations
from data_analysis.statistics import calculate_statistics, generate_statistics_report
from data_analysis.data_processing import fill_missing_values
from anomaly_detector import detect_anomalies, remove_anomalies
from missing_handler.missing_handler import MissingHandler

warnings.filterwarnings('ignore')

# Konfiguracja strony
st.set_page_config(
    page_title="Estymator Stanu Sieci Niskiego NapiÄ™cia",
    page_icon="âš¡",
    layout="wide",
    initial_sidebar_state="expanded"
)

# GÅ‚Ã³wny tytuÅ‚
st.title("âš¡ Estymator Stanu Sieci Niskiego NapiÄ™cia")
st.markdown("### System sztucznej inteligencji do estymacji skrajnych napiÄ™Ä‡ w sieciach nn")

# Menu boczne
st.sidebar.title("Menu")

# GÅ‚Ã³wne zakÅ‚adki
tab_main, tab_anomalies, tab_models, tab_about = st.tabs(["ğŸ  Estymacja napiÄ™Ä‡", "ğŸ” ObsÅ‚uga brakÃ³w i anomalii", "ğŸ§  Modele AI", "ğŸ“š O systemie"])

with tab_anomalies:
    st.header("ğŸ” ObsÅ‚uga brakÃ³w i anomalii")
    st.markdown("""
    W tej sekcji moÅ¼esz wykryÄ‡ i usunÄ…Ä‡ anomalie oraz wypeÅ‚niÄ‡ braki w danych.
    """)
    if 'data' in st.session_state:
        data = st.session_state['data']
        
        # Inicjalizacja MissingHandler
        if 'missing_handler' not in st.session_state:
            st.session_state['missing_handler'] = MissingHandler()
        
        # Sekcja analizy brakÃ³w
        st.subheader("ğŸ“Š Analiza brakÃ³w w danych")
        missing_stats = st.session_state['missing_handler'].get_missing_stats(data)
        
        # WyÅ›wietlanie statystyk brakÃ³w
        if missing_stats['columns_with_missing']:
            st.write("### Kolumny z brakujÄ…cymi wartoÅ›ciami:")
            missing_df = pd.DataFrame({
                'Kolumna': list(missing_stats['columns_with_missing'].keys()),
                'Liczba brakÃ³w': list(missing_stats['columns_with_missing'].values()),
                'Procent brakÃ³w': list(missing_stats['missing_percentages'].values())
            })
            st.dataframe(missing_df.style.format({'Procent brakÃ³w': '{:.2f}%'}))
            
            # WybÃ³r metody wypeÅ‚niania brakÃ³w
            st.subheader("ğŸ”„ WypeÅ‚nianie brakÃ³w")
            method = st.selectbox(
                "Wybierz metodÄ™ wypeÅ‚niania brakÃ³w:",
                ['interpolate', 'forward_fill', 'backward_fill', 'model_impute'],
                format_func=lambda x: {
                    'interpolate': 'Interpolacja liniowa',
                    'forward_fill': 'WypeÅ‚nienie wprzÃ³d',
                    'backward_fill': 'WypeÅ‚nienie wstecz',
                    'model_impute': 'Model uczenia maszynowego'
                }[x]
            )
            
            if st.button("ğŸ”„ WypeÅ‚nij braki"):
                log_operation("WYPEÅNIANIE BRAKÃ“W", f"Rozpoczynam wypeÅ‚nianie brakÃ³w metodÄ… {method}")
                for column in missing_stats['columns_with_missing'].keys():
                    data = st.session_state['missing_handler'].apply_config_strategy(data, column, method)
                st.session_state['data'] = data
                st.success("âœ… Braki zostaÅ‚y wypeÅ‚nione")
                
                # WyÅ›wietl podsumowanie operacji
                summary = st.session_state['missing_handler'].get_imputation_summary()
                st.write("### Podsumowanie operacji wypeÅ‚niania:")
                st.dataframe(summary)
        else:
            st.success("âœ… Brak wartoÅ›ci brakujÄ…cych w danych!")
        
        # Sekcja anomalii
        st.subheader("ğŸ” Wykrywanie anomalii")
        
        # WybÃ³r metody wykrywania anomalii
        anomaly_method = st.selectbox(
            "Wybierz metodÄ™ wykrywania anomalii:",
            ['z_score', 'iqr', 'isolation_forest', 'local_outlier_factor', 'elliptic_envelope'],
            format_func=lambda x: {
                'z_score': 'Z-score (odchylenie standardowe)',
                'iqr': 'IQR (kwartyle)',
                'isolation_forest': 'Isolation Forest',
                'local_outlier_factor': 'Local Outlier Factor',
                'elliptic_envelope': 'Elliptic Envelope'
            }[x]
        )
        
        # Parametry dla metod statystycznych
        if anomaly_method in ['z_score', 'iqr']:
            col1, col2 = st.columns(2)
            with col1:
                if anomaly_method == 'z_score':
                    threshold = st.number_input(
                        "PrÃ³g odchylenia standardowego:",
                        min_value=1.0,
                        max_value=5.0,
                        value=3.0,
                        step=0.1,
                        help="WartoÅ›ci poza tym zakresem bÄ™dÄ… uznane za anomalie"
                    )
                else:  # iqr
                    threshold = st.number_input(
                        "MnoÅ¼nik IQR:",
                        min_value=1.0,
                        max_value=3.0,
                        value=1.5,
                        step=0.1,
                        help="MnoÅ¼nik zakresu miÄ™dzykwartylowego"
                    )
            with col2:
                selected_columns = st.multiselect(
                    "Wybierz kolumny do analizy:",
                    data.select_dtypes(include=[np.number]).columns.tolist(),
                    default=data.select_dtypes(include=[np.number]).columns.tolist()
                )
        else:
            # Parametry dla metod uczenia maszynowego
            contamination = st.slider(
                "Proporcja anomalii w danych:",
                min_value=0.01,
                max_value=0.5,
                value=0.1,
                step=0.01,
                help="Oczekiwana proporcja anomalii w danych (0.01 - 0.5)"
            )
        
        if st.button("ğŸ” Wykryj anomalie"):
            log_operation("DETEKCJA ANOMALII", f"Rozpoczynam wykrywanie anomalii metodÄ… {anomaly_method}", button_name="Wykryj anomalie")
            
            if anomaly_method in ['z_score', 'iqr']:
                # Wykrywanie anomalii metodami statystycznymi
                anomalies = pd.DataFrame()
                stats = {
                    'total_samples': len(data),
                    'anomaly_count': 0,
                    'anomaly_percentage': 0,
                    'method': anomaly_method,
                    'threshold': threshold
                }
                
                for column in selected_columns:
                    if anomaly_method == 'z_score':
                        # Metoda Z-score
                        mean = data[column].mean()
                        std = data[column].std()
                        z_scores = np.abs((data[column] - mean) / std)
                        column_anomalies = data[z_scores > threshold]
                    else:
                        # Metoda IQR
                        q1 = data[column].quantile(0.25)
                        q3 = data[column].quantile(0.75)
                        iqr = q3 - q1
                        lower_bound = q1 - threshold * iqr
                        upper_bound = q3 + threshold * iqr
                        column_anomalies = data[(data[column] < lower_bound) | (data[column] > upper_bound)]
                    
                    anomalies = pd.concat([anomalies, column_anomalies])
                
                # UsuniÄ™cie duplikatÃ³w
                anomalies = anomalies.drop_duplicates()
                
                # Aktualizacja statystyk
                stats['anomaly_count'] = len(anomalies)
                stats['anomaly_percentage'] = (len(anomalies) / len(data)) * 100
                
                # Generowanie podsumowania
                summary = []
                for column in selected_columns:
                    if anomaly_method == 'z_score':
                        mean = data[column].mean()
                        std = data[column].std()
                        z_scores = np.abs((data[column] - mean) / std)
                        column_anomalies = data[z_scores > threshold]
                        summary.append({
                            'column': column,
                            'mean': mean,
                            'std': std,
                            'threshold': threshold,
                            'anomaly_count': len(column_anomalies),
                            'anomaly_percentage': (len(column_anomalies) / len(data)) * 100
                        })
                    else:
                        q1 = data[column].quantile(0.25)
                        q3 = data[column].quantile(0.75)
                        iqr = q3 - q1
                        lower_bound = q1 - threshold * iqr
                        upper_bound = q3 + threshold * iqr
                        column_anomalies = data[(data[column] < lower_bound) | (data[column] > upper_bound)]
                        summary.append({
                            'column': column,
                            'q1': q1,
                            'q3': q3,
                            'iqr': iqr,
                            'lower_bound': lower_bound,
                            'upper_bound': upper_bound,
                            'anomaly_count': len(column_anomalies),
                            'anomaly_percentage': (len(column_anomalies) / len(data)) * 100
                        })
                
                summary_df = pd.DataFrame(summary)
            else:
                # Wykrywanie anomalii metodami uczenia maszynowego
                detector = AnomalyDetector(method=anomaly_method, contamination=contamination)
                anomalies, stats = detector.detect(data)
                summary_df = detector.get_anomaly_summary(data)
            
            st.session_state['anomalies'] = anomalies
            
            # WyÅ›wietlanie statystyk
            st.success(f"âœ… Wykryto {stats['anomaly_count']} anomalii ({stats['anomaly_percentage']:.2f}% danych)")
            
            # WyÅ›wietlanie szczegÃ³Å‚owego podsumowania
            st.write("### SzczegÃ³Å‚owe podsumowanie anomalii:")
            st.dataframe(summary_df)
            
            # WyÅ›wietlanie wykrytych anomalii
            st.write("### Wykryte anomalie:")
            st.dataframe(anomalies)
        
        if st.button("ğŸ—‘ï¸ UsuÅ„ anomalie"):
            log_operation("USUWANIE ANOMALII", "Rozpoczynam usuwanie anomalii", button_name="UsuÅ„ anomalie")
            if 'anomalies' in st.session_state:
                data = remove_anomalies(data, st.session_state['anomalies'])
                st.session_state['data'] = data
                # Zapisz zaktualizowane dane do pliku working_data.csv
                data.to_csv('data/working_data.csv', index=False)
                log_operation("USUWANIE ANOMALII", "Dane po usuniÄ™ciu anomalii zapisane do working_data.csv")
                st.success("âœ… Anomalie zostaÅ‚y usuniÄ™te i zapisane do pliku")
            else:
                st.error("âŒ Najpierw wykryj anomalie")
    else:
        st.info("ğŸ‘† Najpierw wczytaj dane w zakÅ‚adce 'Estymacja napiÄ™Ä‡'")

with tab_models:
    st.header("ğŸ§  Architektury modeli sztucznej inteligencji")
    st.markdown("Poznaj szczegÃ³Å‚y modeli uÅ¼ywanych do estymacji napiÄ™Ä‡ w sieciach niskiego napiÄ™cia")
    
    # WybÃ³r modelu do opisu
    model_choice = st.selectbox(
        "Wybierz model do szczegÃ³Å‚owego opisu:",
        ["LSTM", "PINN", "Transformer", "Hybrid"],
        key="model_desc"
    )
    
    if model_choice == "LSTM":
        st.subheader("ğŸ”„ LSTM (Long Short-Term Memory)")
        
        col1, col2 = st.columns([2, 1])
        with col1:
            st.markdown("""
            **LSTM** to zaawansowana architektura sieci rekurencyjnej, specjalnie zaprojektowana 
            do przetwarzania szeregÃ³w czasowych i sekwencji danych.
            
            **Zastosowanie w estymacji napiÄ™Ä‡:**
            - Przewiduje skrajne napiÄ™cia na podstawie historycznych pomiarÃ³w
            - Uczy siÄ™ wzorcÃ³w obciÄ…Å¼enia i generacji w rÃ³Å¼nych porach dnia
            - Dostrzega sezonowe zmiany w zachowaniu sieci
            
            **Zalety:**
            - âœ… Doskonale radzi sobie z dÅ‚ugimi sekwencjami czasowymi
            - âœ… PamiÄ™ta dÅ‚ugoterminowe zaleÅ¼noÅ›ci w danych
            - âœ… Stabilny podczas treningu
            - âœ… Sprawdzony w zastosowaniach energetycznych
            
            **Wady:**
            - âŒ Wymaga duÅ¼o danych treningowych
            - âŒ Wolniejszy niÅ¼ modele feedforward
            - âŒ Nie uwzglÄ™dnia bezpoÅ›rednio praw fizyki
            """)
            
        with col2:
            # Diagram LSTM
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=[1, 2, 3, 4],
                y=[1, 1, 1, 1],
                mode='markers+text',
                marker=dict(size=40, color='lightblue'),
                text=['Input', 'LSTM', 'LSTM', 'Output'],
                textposition="middle center"
            ))
            fig.add_trace(go.Scatter(
                x=[1, 2, 2, 3, 3, 4],
                y=[1, 1, 1, 1, 1, 1],
                mode='lines',
                line=dict(color='blue', width=2),
                showlegend=False
            ))
            fig.update_layout(
                title="Architektura LSTM",
                showlegend=False,
                xaxis=dict(showgrid=False, showticklabels=False),
                yaxis=dict(showgrid=False, showticklabels=False),
                height=200
            )
            st.plotly_chart(fig, use_container_width=True)
    
    elif model_choice == "PINN":
        st.subheader("âš—ï¸ PINN (Physics-Informed Neural Networks)")
        
        col1, col2 = st.columns([2, 1])
        with col1:
            st.markdown("""
            **PINN** to rewolucyjna architektura Å‚Ä…czÄ…ca uczenie maszynowe z prawami fizyki,
            szczegÃ³lnie przydatna w systemach energetycznych.
            
            **Zastosowanie w estymacji napiÄ™Ä‡:**
            - UwzglÄ™dnia prawa Kirchhoffa i rÃ³wnania przepÅ‚ywu mocy
            - Respektuje fizyczne ograniczenia sieci elektrycznej
            - Zapewnia fizycznie sensowne predykcje napiÄ™Ä‡
            
            **Zalety:**
            - âœ… UwzglÄ™dnia prawa fizyki w predykcjach
            - âœ… Wymaga mniej danych niÅ¼ tradycyjne modele
            - âœ… Generuje fizycznie poprawne wyniki
            - âœ… Lepsze ekstrapolowanie poza dane treningowe
            
            **Wady:**
            - âŒ Bardziej zÅ‚oÅ¼ona implementacja
            - âŒ Wymaga znajomoÅ›ci fizyki systemu
            - âŒ DÅ‚uÅ¼szy czas treningu
            """)
            
        with col2:
            # Diagram PINN
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=[1, 2, 3],
                y=[1, 1, 1],
                mode='markers+text',
                marker=dict(size=40, color='lightgreen'),
                text=['Data', 'Neural Net', 'Output'],
                textposition="middle center"
            ))
            fig.add_trace(go.Scatter(
                x=[2],
                y=[0.5],
                mode='markers+text',
                marker=dict(size=30, color='red'),
                text=['Physics'],
                textposition="middle center"
            ))
            fig.update_layout(
                title="Architektura PINN",
                showlegend=False,
                xaxis=dict(showgrid=False, showticklabels=False),
                yaxis=dict(showgrid=False, showticklabels=False),
                height=200
            )
            st.plotly_chart(fig, use_container_width=True)
    
    elif model_choice == "Transformer":
        st.subheader("ğŸ¯ Transformer z mechanizmem uwagi")
        
        col1, col2 = st.columns([2, 1])
        with col1:
            st.markdown("""
            **Transformer** to najnowoczeÅ›niejsza architektura z mechanizmem uwagi,
            ktÃ³ra rewolucjonizuje przetwarzanie sekwencji.
            
            **Zastosowanie w estymacji napiÄ™Ä‡:**
            - Skupia uwagÄ™ na najwaÅ¼niejszych momentach w historii
            - RÃ³wnolegÅ‚y proces analizy caÅ‚ej sekwencji
            - Doskonale radzi sobie z dÅ‚ugimi zaleÅ¼noÅ›ciami
            
            **Zalety:**
            - âœ… Mechanizm uwagi na kluczowe momenty
            - âœ… RÃ³wnolegÅ‚y processing - szybszy trening
            - âœ… DoskonaÅ‚e dla dÅ‚ugich sekwencji
            - âœ… State-of-the-art w wielu zastosowaniach
            
            **Wady:**
            - âŒ Wymaga bardzo duÅ¼o danych
            - âŒ Wysokie wymagania obliczeniowe
            - âŒ MoÅ¼e przeuczyÄ‡ siÄ™ na maÅ‚ych zbiorach
            """)
            
        with col2:
            # Diagram Transformer
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=[1, 2, 3, 4],
                y=[1, 1.2, 0.8, 1],
                mode='markers+text',
                marker=dict(size=35, color='orange'),
                text=['Input', 'Attention', 'Encoder', 'Output'],
                textposition="middle center"
            ))
            fig.update_layout(
                title="Architektura Transformer",
                showlegend=False,
                xaxis=dict(showgrid=False, showticklabels=False),
                yaxis=dict(showgrid=False, showticklabels=False),
                height=200
            )
            st.plotly_chart(fig, use_container_width=True)
    
    elif model_choice == "Hybrid":
        st.subheader("ğŸ”— Model hybrydowy (Ensemble)")
        
        col1, col2 = st.columns([2, 1])
        with col1:
            st.markdown("""
            **Model hybrydowy** Å‚Ä…czy mocne strony rÃ³Å¼nych architektur w jeden
            potÄ™Å¼ny system predykcyjny.
            
            **Zastosowanie w estymacji napiÄ™Ä‡:**
            - Kombinuje LSTM (pamiÄ™Ä‡) z PINN (fizyka)
            - UÅ¼ywa ensemble learning dla lepszej dokÅ‚adnoÅ›ci
            - Redukuje ryzyko bÅ‚Ä™dÃ³w pojedynczych modeli
            
            **Zalety:**
            - âœ… ÅÄ…czy mocne strony rÃ³Å¼nych podejÅ›Ä‡
            - âœ… WyÅ¼sza dokÅ‚adnoÅ›Ä‡ niÅ¼ pojedyncze modele
            - âœ… WiÄ™ksza odpornoÅ›Ä‡ na bÅ‚Ä™dy
            - âœ… Lepsze uogÃ³lnianie
            
            **Wady:**
            - âŒ WiÄ™ksza zÅ‚oÅ¼onoÅ›Ä‡ obliczeniowa
            - âŒ Trudniejsza interpretacja wynikÃ³w
            - âŒ WiÄ™cej parametrÃ³w do optymalizacji
            """)
            
        with col2:
            # Diagram Hybrid
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=[1, 2, 2, 3],
                y=[1, 1.3, 0.7, 1],
                mode='markers+text',
                marker=dict(size=30, color=['blue', 'green', 'green', 'purple']),
                text=['Input', 'LSTM', 'PINN', 'Combined'],
                textposition="middle center"
            ))
            fig.update_layout(
                title="Architektura Hybrid",
                showlegend=False,
                xaxis=dict(showgrid=False, showticklabels=False),
                yaxis=dict(showgrid=False, showticklabels=False),
                height=200
            )
            st.plotly_chart(fig, use_container_width=True)
    
    # PorÃ³wnanie modeli
    st.subheader("ğŸ“Š PorÃ³wnanie modeli")
    
    comparison_data = {
        'Model': ['LSTM', 'PINN', 'Transformer', 'Hybrid'],
        'DokÅ‚adnoÅ›Ä‡': [85, 88, 90, 95],
        'SzybkoÅ›Ä‡ treningu': [70, 60, 50, 40],
        'Interpretacja': [60, 90, 40, 50],
        'Wymagania danych': [80, 60, 95, 85],
        'StabilnoÅ›Ä‡': [85, 95, 70, 90]
    }
    
    df_comp = pd.DataFrame(comparison_data)
    
    fig = go.Figure()
    
    for i, model in enumerate(df_comp['Model']):
        fig.add_trace(go.Scatterpolar(
            r=[df_comp.iloc[i]['DokÅ‚adnoÅ›Ä‡'], df_comp.iloc[i]['SzybkoÅ›Ä‡ treningu'], 
               df_comp.iloc[i]['Interpretacja'], df_comp.iloc[i]['Wymagania danych'], 
               df_comp.iloc[i]['StabilnoÅ›Ä‡']],
            theta=['DokÅ‚adnoÅ›Ä‡', 'SzybkoÅ›Ä‡ treningu', 'Interpretacja', 'Wymagania danych', 'StabilnoÅ›Ä‡'],
            fill='toself',
            name=model
        ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 100]
            )),
        showlegend=True,
        title="PorÃ³wnanie charakterystyk modeli"
    )
    
    st.plotly_chart(fig, use_container_width=True)

with tab_about:
    st.header("ğŸ“š O systemie estymacji napiÄ™Ä‡")
    
    st.markdown("""
    ## ğŸ¯ Cel systemu
    
    System zostaÅ‚ opracowany w oparciu o najnowsze badania w dziedzinie estymacji napiÄ™Ä‡ 
    w sieciach niskiego napiÄ™cia z wykorzystaniem sztucznej inteligencji.
    
    ## ğŸ”¬ Podstawy naukowe
    
    **Problem:** Wraz z integracjÄ… niesterowalnych ÅºrÃ³deÅ‚ energii (mikroinstalacje PV), 
    nastÄ…piÅ‚o znaczÄ…ce nasycenie sieci nn generacjami, ktÃ³re nie sÄ… bezpoÅ›rednio monitorowane 
    przez Operatora Systemu Dystrybucyjnego.
    
    **RozwiÄ…zanie:** Estymator napiÄ™Ä‡ oparty na AI, ktÃ³ry wykorzystuje dane z pomiarÃ³w 
    elektrycznych w stacji SN/nn do przewidywania skrajnych wartoÅ›ci napiÄ™cia w krytycznych 
    punktach sieci.
    
    ## ğŸ“Š Dane wejÅ›ciowe
    
    System analizuje nastÄ™pujÄ…ce parametry:
    - **PrÄ…dy fazowe** (L1, L2, L3) - pomiary z obwodÃ³w odejÅ›ciowych
    - **NapiÄ™cia fazowe** - pomiary na szynach stacji SN/nn  
    - **Moce czynna i bierna** - caÅ‚kowita moc w stacji
    - **CzÄ™stotliwoÅ›Ä‡ sieci** - stabilnoÅ›Ä‡ systemu elektroenergetycznego
    - **Harmoniczne** - jakoÅ›Ä‡ energii (THD)
    - **Dane generacji PV** - moc i napromieniowanie
    - **Dane meteorologiczne** - temperatura, wilgotnoÅ›Ä‡
    - **Parametry topologiczne** - dÅ‚ugoÅ›ci linii, rezystancje
    
    ## ğŸ¯ Cel predykcji
    
    **SKRAJNE NAPIÄ˜CIE** - gÅ‚Ã³wny parametr estymowany przez system:
    - NajwyÅ¼sze i najniÅ¼sze napiÄ™cia w sieci nn
    - NapiÄ™cia w punktach krytycznych (koÅ„ce linii, przyÅ‚Ä…cza PV)
    - Podstawa do regulacji napiÄ™cia w stacji
    
    ## âš¡ Zastosowania
    
    - **Regulacja napiÄ™cia** - optymalne ustawienie przeÅ‚Ä…cznika zaczepÃ³w
    - **Monitorowanie sieci** - wykrywanie przekroczeÅ„ normatywnych  
    - **Planowanie** - analiza wpÅ‚ywu nowych przyÅ‚Ä…czy PV
    - **Eksploatacja** - wspomaganie decyzji operatora sieci
    """)

with tab_main:
    # Sidebar - konfiguracja
    st.sidebar.header("ğŸ”§ Konfiguracja")
    
    # Przycisk do wczytania przykÅ‚adowych danych
    if st.sidebar.button("ğŸ“Š Wczytaj przykÅ‚adowe dane"):
        try:
            log_operation("WCZYTYWANIE PRZYKÅADOWYCH DANYCH", "Sprawdzanie istnienia pliku")
            if not os.path.exists('data/working_data.csv'):
                log_operation("INICJALIZACJA DANYCH", "Plik nie istnieje, rozpoczynam inicjalizacjÄ™")
                if initialize_working_data():
                    data = pd.read_csv('data/working_data.csv')
                    if data is not None:
                        st.session_state['data'] = data
                        log_operation("INICJALIZACJA DANYCH", f"Zainicjalizowano {len(data)} rekordÃ³w")
                        st.sidebar.success(f"âœ… Wczytano {len(data)} rekordÃ³w przykÅ‚adowych")
                    else:
                        log_operation("BÅÄ„D INICJALIZACJI", "Nie moÅ¼na odczytaÄ‡ zainicjalizowanych danych")
                        st.sidebar.error("âŒ Nie moÅ¼na wczytaÄ‡ danych")
                else:
                    log_operation("BÅÄ„D INICJALIZACJI", "Nie moÅ¼na zainicjalizowaÄ‡ danych")
                    st.sidebar.error("âŒ Nie moÅ¼na zainicjalizowaÄ‡ danych")
            else:
                log_operation("WCZYTYWANIE ISTNIEJÄ„CYCH DANYCH", "Plik juÅ¼ istnieje, odczytujÄ™ dane")
                data = pd.read_csv('data/working_data.csv')
                if data is not None:
                    st.session_state['data'] = data
                    log_operation("WCZYTYWANIE DANYCH", f"Wczytano {len(data)} rekordÃ³w")
                    st.sidebar.success(f"âœ… Wczytano {len(data)} rekordÃ³w")
                else:
                    log_operation("BÅÄ„D ODCZYTU", "Nie moÅ¼na odczytaÄ‡ danych")
                    st.sidebar.error("âŒ Nie moÅ¼na wczytaÄ‡ danych")
        except Exception as e:
            log_operation("BÅÄ„D WCZYTYWANIA", f"WystÄ…piÅ‚ bÅ‚Ä…d: {str(e)}")
            st.sidebar.error(f"âŒ BÅ‚Ä…d: {str(e)}")
    
    # Upload pliku
    uploaded_file = st.sidebar.file_uploader(
        "Wybierz plik CSV z danymi sieci:",
        type=['csv'],
        help="Plik powinien zawieraÄ‡ pomiary z stacji SN/nn oraz dane generacji PV",
        key="uploader"
    )
    
    # Przyciski do obsÅ‚ugi plikÃ³w
    if uploaded_file is not None:
        col1, col2 = st.sidebar.columns(2)
        with col1:
            if st.button("ğŸ“¥ Odczytaj plik", type="primary"):
                log_operation("WCZYTYWANIE PLIKU", f"Wykryto nowy plik: {uploaded_file.name}")
                try:
                    data = pd.read_csv(uploaded_file)
                    log_operation("WCZYTYWANIE PLIKU", f"Odczytano {len(data)} rekordÃ³w z pliku")
                    
                    if save_working_data(data):
                        log_operation("ZAPIS PLIKU", "Dane zapisane do working_data.csv")
                        data = pd.read_csv('data/working_data.csv')
                        if data is not None:
                            st.session_state['data'] = data
                            log_operation("AKTUALIZACJA STANU", "Dane zaktualizowane w session_state")
                            st.sidebar.success(f"âœ… Wczytano {len(data)} rekordÃ³w")
                        else:
                            log_operation("BÅÄ„D ODCZYTU", "Nie moÅ¼na odczytaÄ‡ zapisanych danych")
                            st.error("âŒ Nie moÅ¼na wczytaÄ‡ danych")
                    else:
                        log_operation("BÅÄ„D ZAPISU", "Nie moÅ¼na zapisaÄ‡ danych do pliku")
                        st.error("âŒ Nie moÅ¼na zapisaÄ‡ danych")
                except Exception as e:
                    log_operation("BÅÄ„D WCZYTYWANIA", f"WystÄ…piÅ‚ bÅ‚Ä…d: {str(e)}")
                    st.error(f"âŒ BÅ‚Ä…d wczytywania pliku: {str(e)}")
                    st.stop()
        with col2:
            if st.button("ğŸ”„ PrzeÅ‚aduj dane", type="primary"):
                try:
                    log_operation("PRZEÅADOWANIE DANYCH", "Rozpoczynam odczyt pliku working_data.csv")
                    reloaded_data = pd.read_csv('data/working_data.csv')
                    log_operation("PRZEÅADOWANIE DANYCH", f"Odczytano {len(reloaded_data)} rekordÃ³w")
                    st.session_state['data'] = reloaded_data.copy()
                    log_operation("PRZEÅADOWANIE DANYCH", "Dane skopiowane do session_state")
                    st.sidebar.success("âœ… Dane zostaÅ‚y przeÅ‚adowane!")
                except Exception as e:
                    log_operation("BÅÄ„D PRZEÅADOWANIA", f"WystÄ…piÅ‚ bÅ‚Ä…d: {str(e)}")
                    st.error(f"âŒ BÅ‚Ä…d przeÅ‚adowania danych: {str(e)}")
    else:
        st.sidebar.info("ğŸ‘† Wybierz plik aby wczytaÄ‡ dane")
    
    # Sprawdzenie czy dane sÄ… w session_state
    if 'data' not in st.session_state:
        st.info("ğŸ‘† Wybierz plik CSV z danymi sieci lub wczytaj przykÅ‚adowe dane")
        st.markdown("""
        ### ğŸ“‹ Format danych wejÅ›ciowych
        
        **Wymagane kolumny:**
        - `timestamp` - znacznik czasowy pomiarÃ³w
        - `voltage_extreme` - skrajne napiÄ™cie w sieci [V] (cel predykcji)
        
        ### ğŸ¯ Cel systemu
        
        System estymuje **skrajne napiÄ™cia** w punktach krytycznych sieci nn bazujÄ…c na 
        pomiarach z stacji SN/nn oraz danych generacji fotowoltaicznej.
        """)
        st.stop()
    
    data = st.session_state['data']
    
    # Sprawdzenie kolumn
    required_columns = ['timestamp', 'voltage_extreme']
    missing_columns = [col for col in required_columns if col not in data.columns]
    
    if missing_columns:
        st.error(f"âŒ BrakujÄ…ce kluczowe kolumny: {missing_columns}")
        st.stop()
    
    # Cel predykcji
    target_column = 'voltage_extreme'
    st.sidebar.info(f"ğŸ¯ Cel predykcji: **{target_column}** (skrajne napiÄ™cie w sieci)")
    
    # Parametry modelu
    st.sidebar.subheader("âš™ï¸ Parametry modeli")
    
    # Inicjalizacja parametrÃ³w w session_state
    if 'params' not in st.session_state:
        st.session_state['params'] = {
            'seq_length': 50,
            'batch_size': 32,
            'epochs': 30,
            'learning_rate': 0.001,
            'hidden_size': 64,
            'num_layers': 2
        }
    
    col1, col2 = st.sidebar.columns(2)
    with col1:
        st.session_state['params']['seq_length'] = st.number_input(
            "DÅ‚ugoÅ›Ä‡ sekwencji:", 
            min_value=10, max_value=200, 
            value=st.session_state['params']['seq_length'], 
            step=10
        )
        st.session_state['params']['batch_size'] = st.number_input(
            "Batch size:", 
            min_value=8, max_value=128, 
            value=st.session_state['params']['batch_size'], 
            step=8
        )
        st.session_state['params']['epochs'] = st.number_input(
            "Liczba epok:", 
            min_value=5, max_value=200, 
            value=st.session_state['params']['epochs'], 
            step=5
        )
    
    with col2:
        st.session_state['params']['learning_rate'] = st.number_input(
            "Learning rate:", 
            min_value=0.0001, max_value=0.01, 
            value=st.session_state['params']['learning_rate'], 
            step=0.0001, format="%.4f"
        )
        st.session_state['params']['hidden_size'] = st.number_input(
            "Hidden size:", 
            min_value=16, max_value=256, 
            value=st.session_state['params']['hidden_size'], 
            step=16
        )
        st.session_state['params']['num_layers'] = st.number_input(
            "Liczba warstw:", 
            min_value=1, max_value=5, 
            value=st.session_state['params']['num_layers'], 
            step=1
        )
    
    # WybÃ³r modeli do trenowania
    st.sidebar.subheader("ğŸ§  WybÃ³r modeli")
    
    if 'selected_models' not in st.session_state:
        st.session_state['selected_models'] = ['LSTM', 'PINN']
    
    models_to_train = []
    if st.sidebar.checkbox("LSTM", value='LSTM' in st.session_state['selected_models']):
        models_to_train.append("LSTM")
    if st.sidebar.checkbox("PINN", value='PINN' in st.session_state['selected_models']):
        models_to_train.append("PINN")
    if st.sidebar.checkbox("Transformer", value='Transformer' in st.session_state['selected_models']):
        models_to_train.append("Transformer")
    if st.sidebar.checkbox("Hybrid", value='Hybrid' in st.session_state['selected_models']):
        models_to_train.append("Hybrid")
    
    st.session_state['selected_models'] = models_to_train
    
    # Przycisk trenowania
    train_button = st.sidebar.button("ğŸš€ Rozpocznij trening", type="primary")
    
    # Przycisk resetowania danych do stanu poczÄ…tkowego
    if st.sidebar.button("ğŸ”„ Resetuj dane do oryginaÅ‚u"):
        try:
            log_operation("RESET DANYCH", "Rozpoczynam reset do oryginalnych danych")
            data = pd.read_csv('data/network_voltage_data.csv')
            log_operation("RESET DANYCH", f"Odczytano {len(data)} rekordÃ³w z oryginalnego pliku")
            data.to_csv('data/working_data.csv', index=False)
            log_operation("RESET DANYCH", "Zapisano dane do working_data.csv")
            data = pd.read_csv('data/working_data.csv')
            st.session_state['data'] = data
            log_operation("RESET DANYCH", "Zaktualizowano session_state")
            st.sidebar.success("âœ… Dane zresetowane do oryginaÅ‚u!")
        except Exception as e:
            log_operation("BÅÄ„D RESETU", f"WystÄ…piÅ‚ bÅ‚Ä…d: {str(e)}")
            st.sidebar.error(f"âŒ BÅ‚Ä…d resetowania danych: {str(e)}")
    
    # GÅ‚Ã³wna czÄ™Å›Ä‡ aplikacji
    if not train_button and 'training_results' not in st.session_state:
        # Analiza danych
        st.header("ğŸ“Š Analiza danych sieci niskiego napiÄ™cia")
        
        # Podstawowe statystyki
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Liczba pomiarÃ³w", f"{len(data):,}")
        with col2:
            if 'timestamp' in data.columns:
                data['datetime'] = pd.to_datetime(data['timestamp'])
                start_time = data['datetime'].min()
                end_time = data['datetime'].max()
                period = (end_time - start_time).days
                st.metric("Okres [dni]", f"{period}")
            else:
                st.metric("Okres", "N/A")
        with col3:
            st.metric("Åšrednie napiÄ™cie", f"{data['voltage_extreme'].mean():.1f} V")
        with col4:
            voltage_violations = ((data['voltage_extreme'] < 207) | (data['voltage_extreme'] > 253)).sum()
            st.metric("Przekroczenia Â±10%", f"{voltage_violations}")
        
        # WybÃ³r typu analizy
        analysis_type = st.radio(
            "Wybierz typ analizy",
            ["Szeregi czasowe", "Korelacje", "Statystyki opisowe", "Analiza rozkÅ‚adÃ³w"]
        )
        
        if analysis_type == "Szeregi czasowe":
            # GÅ‚Ã³wny wykres napiÄ™Ä‡ skrajnych
            data['datetime'] = pd.to_datetime(data['timestamp'])
            
            # Lista dostÄ™pnych kolumn numerycznych
            numeric_columns = data.select_dtypes(include=[np.number]).columns.tolist()
            
            # WybÃ³r kolumny do wyÅ›wietlenia
            selected_column = st.selectbox(
                "Wybierz parametr do wyÅ›wietlenia:",
                numeric_columns,
                index=numeric_columns.index('voltage_extreme') if 'voltage_extreme' in numeric_columns else 0
            )
            
            # Konfiguracja wykresu
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=data['datetime'], 
                y=data[selected_column],
                name=selected_column,
                line=dict(color='red', width=1)
            ))
            
            # Dodanie linii normatywnych tylko dla voltage_extreme
            if selected_column == 'voltage_extreme':
                fig.add_hline(y=253, line_dash="dash", line_color="orange", 
                             annotation_text="GÃ³rna granica (+10%)")
                fig.add_hline(y=207, line_dash="dash", line_color="blue", 
                             annotation_text="Dolna granica (-10%)")
            
            # Konfiguracja tytuÅ‚u i osi
            column_names = {
                'voltage_extreme': 'Skrajne napiÄ™cie',
                'current_L1': 'PrÄ…d fazy L1',
                'current_L2': 'PrÄ…d fazy L2',
                'current_L3': 'PrÄ…d fazy L3',
                'voltage_L1': 'NapiÄ™cie fazy L1',
                'voltage_L2': 'NapiÄ™cie fazy L2',
                'voltage_L3': 'NapiÄ™cie fazy L3',
                'active_power_total': 'Moc czynna caÅ‚kowita',
                'reactive_power_total': 'Moc bierna caÅ‚kowita',
                'frequency': 'CzÄ™stotliwoÅ›Ä‡',
                'voltage_thd': 'THD napiÄ™cia',
                'current_thd': 'THD prÄ…du',
                'irradiance': 'Napromieniowanie',
                'pv_power': 'Moc PV',
                'temperature': 'Temperatura',
                'humidity': 'WilgotnoÅ›Ä‡',
                'line_length_total': 'CaÅ‚kowita dÅ‚ugoÅ›Ä‡ linii',
                'line_resistance': 'Rezystancja linii',
                'pv_connections': 'Liczba przyÅ‚Ä…czy PV'
            }
            
            # Ustawienie tytuÅ‚u i etykiet osi
            title = column_names.get(selected_column, selected_column)
            y_label = {
                'voltage_extreme': 'NapiÄ™cie [V]',
                'current_L1': 'PrÄ…d [A]',
                'current_L2': 'PrÄ…d [A]',
                'current_L3': 'PrÄ…d [A]',
                'voltage_L1': 'NapiÄ™cie [V]',
                'voltage_L2': 'NapiÄ™cie [V]',
                'voltage_L3': 'NapiÄ™cie [V]',
                'active_power_total': 'Moc [kW]',
                'reactive_power_total': 'Moc [kVAr]',
                'frequency': 'CzÄ™stotliwoÅ›Ä‡ [Hz]',
                'voltage_thd': 'THD [%]',
                'current_thd': 'THD [%]',
                'irradiance': 'Napromieniowanie [W/mÂ²]',
                'pv_power': 'Moc [kW]',
                'temperature': 'Temperatura [Â°C]',
                'humidity': 'WilgotnoÅ›Ä‡ [%]',
                'line_length_total': 'DÅ‚ugoÅ›Ä‡ [m]',
                'line_resistance': 'Rezystancja [Î©]',
                'pv_connections': 'Liczba przyÅ‚Ä…czy'
            }.get(selected_column, 'WartoÅ›Ä‡')
            
            fig.update_layout(
                title=f"{title} w czasie",
                xaxis_title="Czas",
                yaxis_title=y_label,
                height=500
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Dodanie statystyk pod wykresem
            st.subheader("ğŸ“Š Statystyki")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Åšrednia", f"{data[selected_column].mean():.2f}")
            with col2:
                st.metric("Minimum", f"{data[selected_column].min():.2f}")
            with col3:
                st.metric("Maximum", f"{data[selected_column].max():.2f}")
            with col4:
                st.metric("Odchylenie std.", f"{data[selected_column].std():.2f}")
        
        elif analysis_type == "Korelacje":
            st.subheader("Analiza korelacji")
            if 'data' in st.session_state:
                corr_matrix = create_correlation_matrix(st.session_state.data)
                st.plotly_chart(corr_matrix, use_container_width=True)
                
                # SzczegÃ³Å‚owa analiza korelacji
                st.subheader("SzczegÃ³Å‚owa analiza korelacji")
                correlations = analyze_correlations(st.session_state.data)
                st.write(correlations)
        
        elif analysis_type == "Statystyki opisowe":
            st.subheader("Statystyki opisowe")
            if 'data' in st.session_state:
                stats = calculate_statistics(st.session_state.data)
                st.write(stats)
                
                # Generowanie raportu
                if st.button("Generuj raport statystyczny"):
                    report = generate_statistics_report(st.session_state.data)
                    st.download_button(
                        label="Pobierz raport",
                        data=report,
                        file_name="statistics_report.html",
                        mime="text/html"
                    )
        
        else:  # Analiza rozkÅ‚adÃ³w
            st.subheader("Analiza rozkÅ‚adÃ³w")
            if 'data' in st.session_state:
                selected_column = st.selectbox(
                    "Wybierz kolumnÄ™ do analizy",
                    st.session_state.data.select_dtypes(include=[np.number]).columns
                )
                
                # Histogram
                fig = px.histogram(
                    st.session_state.data,
                    x=selected_column,
                    title=f"RozkÅ‚ad {selected_column}",
                    nbins=50
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # Box plot
                fig = px.box(
                    st.session_state.data,
                    y=selected_column,
                    title=f"Box plot {selected_column}"
                )
                st.plotly_chart(fig, use_container_width=True)
    
    elif train_button or 'training_results' in st.session_state:
        # Sekcja treningu
        st.header("ğŸ§  Trening modeli AI")
        
        if train_button:
            if not models_to_train:
                st.error("âŒ Wybierz przynajmniej jeden model do trenowania!")
                st.stop()
            
            # Przygotowanie danych
            with st.spinner("Przygotowywanie danych..."):
                X, y, feature_names = create_sequences(data, st.session_state['params']['seq_length'], target_column)
                
                # PodziaÅ‚ na zbiory
                train_size = int(0.8 * len(X))
                X_train, X_test = X[:train_size], X[train_size:]
                y_train, y_test = y[:train_size], y[train_size:]
                
                st.success("âœ… Dane przygotowane pomyÅ›lnie")
            
            # Trening modeli
            results = {}
            progress_bar = st.progress(0)
            
            for i, model_name in enumerate(models_to_train):
                with st.spinner(f"Trenowanie modelu {model_name}..."):
                    predictions = simulate_model_training(X_train, y_train, X_test, y_test, model_name, st.session_state['params'])
                    metrics = calculate_metrics(y_test, predictions)
                    
                    results[model_name] = {
                        'predictions': predictions,
                        'actuals': y_test,
                        'metrics': metrics
                    }
                    
                    progress_bar.progress((i + 1) / len(models_to_train))
            
            st.session_state['training_results'] = results
            st.session_state['test_data'] = {'X_test': X_test, 'y_test': y_test}
            
            st.success("âœ… Trening zakoÅ„czony!")
        
        # WyÅ›wietlanie wynikÃ³w
        if 'training_results' in st.session_state:
            results = st.session_state['training_results']
            
            st.subheader("ğŸ“ˆ Wyniki treningu")
            
            # Metryki
            metrics_df = pd.DataFrame({
                model: results[model]['metrics'] 
                for model in results.keys()
            }).T
            
            # Kolorowanie najlepszych wynikÃ³w
            styled_df = metrics_df.style.highlight_min(subset=['MSE', 'MAE', 'RMSE', 'MAPE (%)', 'Max Error'], color='lightgreen')
            styled_df = styled_df.highlight_max(subset=['RÂ²'], color='lightgreen')
            
            st.dataframe(styled_df, use_container_width=True)
            
            # Najlepszy model
            best_model = min(results.keys(), key=lambda x: results[x]['metrics']['MSE'])
            best_metrics = results[best_model]['metrics']
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ğŸ† Najlepszy model", best_model)
            with col2:
                st.metric("ğŸ“Š RÂ² Score", f"{best_metrics['RÂ²']:.3f}")
            with col3:
                st.metric("ğŸ“‰ MAPE", f"{best_metrics['MAPE (%)']:.1f}%")
            
            # Wykresy predykcji
            st.subheader("ğŸ“ˆ Wizualizacja predykcji")
            
            for model_name in results.keys():
                fig = go.Figure()
                
                # Rzeczywiste wartoÅ›ci
                fig.add_trace(go.Scatter(
                    y=results[model_name]['actuals'],
                    name='Rzeczywiste wartoÅ›ci',
                    line=dict(color='blue', width=2)
                ))
                
                # Predykcje
                fig.add_trace(go.Scatter(
                    y=results[model_name]['predictions'],
                    name=f'Predykcje {model_name}',
                    line=dict(color='red', width=2)
                ))
                
                fig.update_layout(
                    title=f"Predykcje vs Rzeczywiste wartoÅ›ci - {model_name}",
                    xaxis_title="PrÃ³bka",
                    yaxis_title="NapiÄ™cie [V]",
                    height=400
                )
                
                st.plotly_chart(fig, use_container_width=True)
            
            # INTELIGENTNE REKOMENDACJE
            st.subheader("ğŸ¯ Inteligentne rekomendacje")
            
            recommendations = generate_recommendations(results, st.session_state['params'])
            
            if recommendations:
                st.markdown("### ğŸ’¡ Sugerowane ulepszenia:")
                
                for rec in recommendations:
                    with st.expander(f"{rec['category']}: {rec['issue']}"):
                        st.write(f"**Problem:** {rec['issue']}")
                        st.write(f"**Rekomendacja:** {rec['recommendation']}")
                        
                        if rec['action'] != 'none' and rec['action'] != 'add_model':
                            if st.button(f"Zastosuj: {rec['action']} = {rec['new_value']}", key=f"apply_{rec['action']}"):
                                st.session_state['params'][rec['action']] = rec['new_value']
                                st.success(f"âœ… Zaktualizowano {rec['action']} na {rec['new_value']}")
                                st.rerun()
                        elif rec['action'] == 'add_model':
                            if st.button(f"Dodaj model {rec['new_value']}", key=f"add_{rec['new_value']}"):
                                if rec['new_value'] not in st.session_state['selected_models']:
                                    st.session_state['selected_models'].append(rec['new_value'])
                                    st.success(f"âœ… Dodano model {rec['new_value']} do treningu")
                                    st.rerun()
                
                # Przycisk do ponownego treningu z sugerowanymi parametrami
                st.markdown("---")
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ğŸ”„ Trenuj ponownie z nowymi parametrami", type="primary"):
                        del st.session_state['training_results']
                        st.rerun()
                
                with col2:
                    if st.button("ğŸ“Š Reset parametrÃ³w"):
                        st.session_state['params'] = {
                            'seq_length': 50,
                            'batch_size': 32,
                            'epochs': 30,
                            'learning_rate': 0.001,
                            'hidden_size': 64,
                            'num_layers': 2
                        }
                        st.success("âœ… Parametry zresetowane")
                        st.rerun()
            
            else:
                st.success("ğŸ‰ DoskonaÅ‚e wyniki! Model jest gotowy do wdroÅ¼enia.")
                
                # Podsumowanie koÅ„cowe
                st.subheader("ğŸ“‹ Podsumowanie koÅ„cowe")
                
                best_r2 = best_metrics['RÂ²']
                best_mape = best_metrics['MAPE (%)']
                
                if best_r2 > 0.9:
                    st.success(f"âœ… **DoskonaÅ‚a jakoÅ›Ä‡ predykcji** (RÂ² = {best_r2:.3f})")
                elif best_r2 > 0.8:
                    st.warning(f"âš ï¸ **Dobra jakoÅ›Ä‡ predykcji** (RÂ² = {best_r2:.3f})")
                else:
                    st.error(f"âŒ **Niska jakoÅ›Ä‡ predykcji** (RÂ² = {best_r2:.3f})")
                
                if best_mape < 5:
                    st.success(f"âœ… **Bardzo niski bÅ‚Ä…d** (MAPE = {best_mape:.1f}%)")
                elif best_mape < 10:
                    st.warning(f"âš ï¸ **Akceptowalny bÅ‚Ä…d** (MAPE = {best_mape:.1f}%)")
                else:
                    st.error(f"âŒ **Wysoki bÅ‚Ä…d** (MAPE = {best_mape:.1f}%)")
                
                st.info(f"ğŸ† **Rekomendowany model:** {best_model}")